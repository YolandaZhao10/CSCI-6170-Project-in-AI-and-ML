{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YolandaZhao10/CSCI-6170-Project-in-AI-and-ML/blob/main/lab01/lab_1_part_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EumzRatBV57m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed106a38-04e6-4436-c9a4-34d215b2e9ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'creditcardfraud' dataset.\n",
            "Path to dataset files: /kaggle/input/creditcardfraud\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "df = pd.read_csv(os.path.join(path, \"creditcard.csv\"))\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "ntoB16neWWU5",
        "outputId": "fe9b97b5-8999-4300-ad1a-c063ee46f314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5afa6cf4-443d-4e30-8079-8bda9eab81d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5afa6cf4-443d-4e30-8079-8bda9eab81d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5afa6cf4-443d-4e30-8079-8bda9eab81d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5afa6cf4-443d-4e30-8079-8bda9eab81d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted = df.sort_values('Time').reset_index(drop=True)\n",
        "print(\"Sorted by Time for temporal split\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zoXVNn7ZybC",
        "outputId": "5776f870-2783-46ef-d82c-abe709628657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted by Time for temporal split\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx = int(0.8 * len(df_sorted))\n",
        "X_train = df_sorted.drop('Class', axis=1).iloc[:split_idx]\n",
        "y_train = df_sorted['Class'].iloc[:split_idx]\n",
        "X_test = df_sorted.drop('Class', axis=1).iloc[split_idx:]\n",
        "y_test = df_sorted['Class'].iloc[split_idx:]\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Fraud: {y_train.mean():.4f}\")\n",
        "print(f\"Test: {X_test.shape}, Fraud: {y_test.mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnRhxMLOZpfK",
        "outputId": "eaeb456c-17fc-4bf7-a19e-1c22f7982ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (227845, 30), Fraud: 0.0018\n",
            "Test: (56962, 30), Fraud: 0.0013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "from itertools import product\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "XdTNwxdqZ3SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb_pipe = Pipeline([('scaler', StandardScaler()), ('gnb', GaussianNB())])\n",
        "gnb_pipe.fit(X_train, y_train)\n",
        "y_pred_gnb = gnb_pipe.predict(X_test)\n",
        "baseline_f1 = f1_score(y_test, y_pred_gnb, zero_division=0)\n",
        "print(f\"Baseline GNB Test F1: {baseline_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARmWh1GIZsGU",
        "outputId": "84b5f36f-10e6-40d2-c972-a72c1ac418bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline GNB Test F1: 0.0974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from itertools import product\n",
        "import pandas as pd\n",
        "#227k train samples (99.83% normal, 0.17% fraud)\n",
        "#split into 3 chunks\n",
        "#Same fraud ratio each (Stratified)\n",
        "\n",
        "param_combos = [0.01, 0.1, 1.0]#3 settings\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)#3 fold cv\n",
        "results_log = []\n",
        "print(\"Fast 3-fold CV Tuning (F1 on train):\")\n",
        "for C in param_combos:\n",
        "    svm_pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svm', LinearSVC(C=C, class_weight='balanced', random_state=42,\n",
        "                         dual=False, max_iter=5000, tol=1e-3))\n",
        "    ])\n",
        "\n",
        "    cv_scores = cross_val_score(svm_pipe, X_train, y_train, cv=cv, scoring='f1', n_jobs=-1)\n",
        "    cv_mean = cv_scores.mean()\n",
        "\n",
        "    print(f\"LinearSVC(C={C}): CV F1={cv_mean:.4f} (±{cv_scores.std():.4f})\")\n",
        "    results_log.append({'Variant': f'C={C}', 'CV_F1_mean': cv_mean, 'CV_std': cv_scores.std()})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKUtv_TBZL4k",
        "outputId": "21a65d1c-4baf-4e76-c673-0df6d9d6d1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast 3-fold CV Tuning (F1 on train):\n",
            "LinearSVC(C=0.01): CV F1=0.1566 (±0.0141)\n",
            "LinearSVC(C=0.1): CV F1=0.1565 (±0.0138)\n",
            "LinearSVC(C=1.0): CV F1=0.1564 (±0.0137)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "models = [\n",
        "    (\"Baseline (GaussianNB)\", GaussianNB()),\n",
        "    (\"Week 2 SVM (LinearSVC)\", LinearSVC(C=0.01, dual='auto', random_state=42))\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, model in models:\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"F1 Mean\": scores.mean(),\n",
        "        \"F1 Std\": scores.std()\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(results)\n",
        "print(comparison_df)\n",
        "\n",
        "diff = results[1]['F1 Mean'] - results[0]['F1 Mean']\n",
        "print(f\"\\nNet Change in F1 Score: {diff:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvcgfNbJhyua",
        "outputId": "f7483610-db92-49ec-ff99-274718e3253d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Model   F1 Mean    F1 Std\n",
            "0   Baseline (GaussianNB)  0.219475  0.004403\n",
            "1  Week 2 SVM (LinearSVC)  0.656347  0.021926\n",
            "\n",
            "Net Change in F1 Score: 0.4369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "\n",
        "experiments = [\n",
        "    {\"Name\": \"GaussianNB (Baseline)\", \"Model\": GaussianNB()},\n",
        "    {\"Name\": \"LinearSVC\", \"Model\": LinearSVC(C=0.01, dual='auto', random_state=SEED)},\n",
        "    {\"Name\": \"LinearSVC\", \"Model\": LinearSVC(C=0.1, dual='auto', random_state=SEED)},\n",
        "    {\"Name\": \"LinearSVC\", \"Model\": LinearSVC(C=1.0, dual='auto', random_state=SEED)},\n",
        "]\n",
        "\n",
        "log_entries = []\n",
        "\n",
        "for exp in experiments:\n",
        "    scores = cross_val_score(exp[\"Model\"], X_train, y_train, cv=cv, scoring='f1')\n",
        "\n",
        "    log_entries.append({\n",
        "        \"Model\": exp[\"Name\"],\n",
        "        \"Params\": f\"C={exp['Model'].C}\" if \"LinearSVC\" in exp[\"Name\"] else \"Default\",\n",
        "        \"Mean F1\": round(scores.mean(), 4),\n",
        "        \"Std Dev\": round(scores.std(), 4),\n",
        "        \"Seed\": SEED if \"LinearSVC\" in exp[\"Name\"] else \"Default\"\n",
        "    })\n",
        "\n",
        "experiment_log = pd.DataFrame(log_entries)\n",
        "print(experiment_log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EBmEeGJh1Th",
        "outputId": "081dd682-9487-48bf-a042-9f97e164025c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Model   Params  Mean F1  Std Dev     Seed\n",
            "0  GaussianNB (Baseline)  Default   0.2195   0.0044  Default\n",
            "1              LinearSVC   C=0.01   0.6563   0.0219       42\n",
            "2              LinearSVC    C=0.1   0.6603   0.0223       42\n",
            "3              LinearSVC    C=1.0   0.6452   0.0395       42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part D**"
      ],
      "metadata": {
        "id": "KhJ41aPRXKJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first trained the base classifier on the full training set.\n",
        "\n",
        "To reduce computational cost, we calibrated probabilities using Platt scaling on a small held-out stratified subset of the training data (cv=\"prefit\")."
      ],
      "metadata": {
        "id": "_3f_slRzYRmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(os.path.join(path, \"creditcard.csv\"))\n",
        "\n",
        "target = \"Class\"\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target].astype(int)\n",
        "\n",
        "# Train / Test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.30,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    test_size=0.25,      # 25% of train becomes validation\n",
        "    random_state=42,\n",
        "    stratify=y_train     # IMPORTANT for classification\n",
        ")\n",
        "\n",
        "# Build a base classifier\n",
        "\n",
        "base_clf = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lr\", LogisticRegression(\n",
        "        max_iter=2000,\n",
        "        solver=\"lbfgs\",\n",
        "        class_weight=\"balanced\",   # helpful for extreme imbalance\n",
        "        n_jobs=None                # keep default; lbfgs ignores n_jobs anyway\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Fit base model on FULL training data\n",
        "base_clf.fit(X_train, y_train)\n",
        "\n",
        "# Create a small, stratified calibration subset from training data\n",
        "# calibrate on ~5% held-out data\n",
        "\n",
        "cal_frac = 0.05  # 5% for calibration; you can try 0.02 if still slow\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=cal_frac, random_state=42)\n",
        "cal_idx, _ = next(sss.split(X_train, y_train))\n",
        "\n",
        "X_cal = X_train.iloc[cal_idx]\n",
        "y_cal = y_train.iloc[cal_idx]\n",
        "\n",
        "# Calibrate using Platt scaling (sigmoid) with cv=\"prefit\"\n",
        "#    meaning: base_clf is already fit; we only learn calibration mapping here\n",
        "\n",
        "calibrated_clf = CalibratedClassifierCV(\n",
        "    estimator=base_clf,\n",
        "    method=\"sigmoid\",\n",
        "    cv=\"prefit\"\n",
        ")\n",
        "\n",
        "calibrated_clf.fit(X_cal, y_cal)\n",
        "\n",
        "# Predict calibrated probabilities on test set\n",
        "y_prob = calibrated_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Decision thresholding under a simple cost model\n",
        "#    tau = C_FP / (C_FP + C_FN)\n",
        "C_FP = 1   # cost of false positive (flagging normal as fraud)\n",
        "C_FN = 10  # cost of false negative (missing fraud)\n",
        "\n",
        "tau = C_FP / (C_FP + C_FN)\n",
        "y_pred_cost = (y_prob >= tau).astype(int)\n",
        "\n",
        "# Quick evaluation outputs\n",
        "print(f\"Calibration subset fraction: {cal_frac:.2%}\")\n",
        "print(f\"Cost-based threshold tau = {tau:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion matrix (cost-thresholded):\")\n",
        "print(confusion_matrix(y_test, y_pred_cost))\n",
        "\n",
        "print(\"\\nClassification report (cost-thresholded):\")\n",
        "print(classification_report(y_test, y_pred_cost, digits=4))\n"
      ],
      "metadata": {
        "id": "B952M2Y7XEoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff28947b-77f7-4c95-b180-3b6456bfe8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibration subset fraction: 5.00%\n",
            "Cost-based threshold tau = 0.0909\n",
            "\n",
            "Confusion matrix (cost-thresholded):\n",
            "[[85276    19]\n",
            " [   35   113]]\n",
            "\n",
            "Classification report (cost-thresholded):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9996    0.9998    0.9997     85295\n",
            "           1     0.8561    0.7635    0.8071       148\n",
            "\n",
            "    accuracy                         0.9994     85443\n",
            "   macro avg     0.9278    0.8816    0.9034     85443\n",
            "weighted avg     0.9993    0.9994    0.9993     85443\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We calibrated the model’s predicted probabilities using Platt scaling (sigmoid) with CalibratedClassifierCV on a held-out stratified subset of the training data (cv=\"prefit\") to reduce computational cost.\n",
        "Under a simple cost model with false-positive cost $C_{FP}$ = 1 and false-negative cost $C_{FN}$ = 10\n",
        ", the optimal threshold is 0.0909.\n",
        "Using this cost-derived threshold, the confusion matrix on the test set is TN=85277, FP=18, FN=35, TP=113.\n",
        "For the fraud class, precision is 0.8626 and recall is 0.7635, reflecting a cost-sensitive trade-off that prioritizes reducing false negatives.\n",
        "Accuracy is high due to class imbalance, so we primarily interpret performance using the fraud-class precision/recall and the cost-based thresholding rule."
      ],
      "metadata": {
        "id": "wPOQDcRwdI19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def expected_cost(y_true, y_prob, threshold):\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return C_FP * fp + C_FN * fn\n",
        "\n",
        "thresholds = np.linspace(0.01, 0.99, 99)\n",
        "y_val_prob = calibrated_clf.predict_proba(X_val)[:, 1]\n",
        "costs = [expected_cost(y_val, y_val_prob, t) for t in thresholds]\n",
        "\n",
        "best_threshold = thresholds[np.argmin(costs)]\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def report_metrics(y_true, y_prob, threshold):\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"precision\": precision_score(y_true, y_pred),\n",
        "        \"recall\": recall_score(y_true, y_pred),\n",
        "        \"f1\": f1_score(y_true, y_pred),\n",
        "        \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "# Default threshold = 0.5\n",
        "default_threshold = 0.5\n",
        "default_metrics = report_metrics(\n",
        "    y_test,\n",
        "    calibrated_clf.predict_proba(X_test)[:,1],\n",
        "    default_threshold\n",
        ")\n",
        "\n",
        "cm = default_metrics[\"confusion_matrix\"]\n",
        "\n",
        "print(\"Default Threshold Evaluation\")\n",
        "print(f\"Threshold : {default_threshold:.3f}\")\n",
        "print(f\"Accuracy  : {default_metrics['accuracy']:.4f}\")\n",
        "print(f\"Precision : {default_metrics['precision']:.4f}\")\n",
        "print(f\"Recall    : {default_metrics['recall']:.4f}\")\n",
        "print(f\"F1-score  : {default_metrics['f1']:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "\n",
        "# Chosen threshold\n",
        "chosen_metrics = report_metrics(y_test, calibrated_clf.predict_proba(X_test)[:,1], best_threshold)\n",
        "cm = chosen_metrics[\"confusion_matrix\"]\n",
        "\n",
        "print(\"Chosen Threshold Evaluation\")\n",
        "print(f\"Threshold : {best_threshold:.3f}\")\n",
        "print(f\"Accuracy  : {chosen_metrics['accuracy']:.4f}\")\n",
        "print(f\"Precision : {chosen_metrics['precision']:.4f}\")\n",
        "print(f\"Recall    : {chosen_metrics['recall']:.4f}\")\n",
        "print(f\"F1-score  : {chosen_metrics['f1']:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n"
      ],
      "metadata": {
        "id": "gYe_KWt7XqW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da15b55b-821f-4be5-9b11-52ecfc4b8e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Threshold Evaluation\n",
            "Threshold : 0.500\n",
            "Accuracy  : 0.9992\n",
            "Precision : 0.8704\n",
            "Recall    : 0.6351\n",
            "F1-score  : 0.7344\n",
            "\n",
            "Confusion Matrix:\n",
            "[[85281    14]\n",
            " [   54    94]]\n",
            "Chosen Threshold Evaluation\n",
            "Threshold : 0.010\n",
            "Accuracy  : 0.9992\n",
            "Precision : 0.7597\n",
            "Recall    : 0.7905\n",
            "F1-score  : 0.7748\n",
            "\n",
            "Confusion Matrix:\n",
            "[[85258    37]\n",
            " [   31   117]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We selected the decision threshold using validation predictions to balance the trade-off between false positives and false negatives. Compared to the default threshold, the chosen threshold significantly improves recall (from 0.6351 to 0.7905), reducing the number of false negatives from 54 to 31. Although this comes at the cost of lower precision (from 0.8704 to 0.7597) and a modest increase in false positives, the overall F1-score improves from 0.7344 to 0.7748. This trade-off is appropriate in settings where missing positive cases is more costly than flagging additional negatives as positives."
      ],
      "metadata": {
        "id": "98m6Rluyg7XN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRTajpsxXsSz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}