{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YolandaZhao10/CSCI-6170-Project-in-AI-and-ML/blob/main/hw1/homework_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Advanced Objective Function and Use Case"
      ],
      "metadata": {
        "id": "bQWDj97YXnVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1.1"
      ],
      "metadata": {
        "id": "bevrfXSEU5j6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Assumption\n",
        "Given a binary classification dataset\n",
        "$\\mathscr D =\\{(x_i,y_i)\\}_{i=1}^N,\\quad\n",
        "x_i\\in\\mathbb R^d,\\; y_i\\in\\{0,1\\}$,\n",
        "logistic regression models the conditional probability as\n",
        "$$\n",
        "p(y_i=1\\mid x_i;w)=\\sigma(w^\\top x_i),\n",
        "\\quad\n",
        "\\sigma(z)=\\frac{1}{1+e^{-z}}.\n",
        "$$\n",
        "\n",
        "Base on probability for $y_i = 1$, we can also get conditional probability for $y_i = 0$.\n",
        "\n",
        "$$\n",
        "p(y_i=0\\mid x_i;w)=1-\\sigma(w^\\top x_i).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## Maximum Likelihood Estimation\n",
        "Each label $y_i$ is assumed to follow a Bernoulli distribution. The conditional likelihood can be written compactly as\n",
        "\n",
        "$$\n",
        "p(y_i\\mid x_i;w)\n",
        "=\\sigma(w^\\top x_i)^{y_i}\n",
        "\\left(1-\\sigma(w^\\top x_i)\\right)^{1-y_i}.\n",
        "$$\n",
        "\n",
        "Assuming the samples are i.i.d., the likelihood over the entire dataset is\n",
        "\n",
        "$$\n",
        "\\mathscr{L}(w)\n",
        "=\\prod_{i=1}^N p(y_i\\mid x_i;w)\n",
        "=\\prod_{i=1}^N\n",
        "\\sigma(w^\\top x_i)^{y_i}\n",
        "\\left(1-\\sigma(w^\\top x_i)\\right)^{1-y_i}.\n",
        "$$\n",
        "\n",
        "Then, we can taking the logarithm of the likelihood yields the log-likelihood:\n",
        "\n",
        "$$\n",
        "\\ell(w)\n",
        "=\\log \\mathscr{L}(w)\n",
        "=\\sum_{i=1}^N\n",
        "\\Big[\n",
        "y_i \\log \\sigma(w^\\top x_i)\n",
        "+(1-y_i)\\log\\left(1-\\sigma(w^\\top x_i)\\right)\n",
        "\\Big].\n",
        "$$\n",
        "\n",
        "Maximum Likelihood Estimation seeks the parameter $w$ that maximizes the log-likelihood:\n",
        "\n",
        "$$\n",
        "w_{\\text{MLE}}=\\arg\\max_w \\ell(w).\n",
        "$$\n",
        "\n",
        "\n",
        "## Get Objective Function of Logistic Regression Under MLE\n",
        "Maximizing the log-likelihood is equivalent to minimizing the negative log-likelihood. Therefore, the objective function of logistic regression under MLE is\n",
        "\n",
        "$$\n",
        "J_{\\text{MLE}}(w)\n",
        "=-\\ell(w)\n",
        "=\\sum_{i=1}^N\n",
        "\\Big[\n",
        "- y_i \\log \\sigma(w^\\top x_i)\n",
        "-(1-y_i)\\log\\left(1-\\sigma(w^\\top x_i)\\right)\n",
        "\\Big].\n",
        "$$\n",
        "\n",
        "This objective function is known as the **logistic loss** or **binary cross-entropy loss**.\n",
        "\n",
        "## MLE vs. MAP for Logistic Regression\n",
        "\n",
        "\n",
        "**Definition**: Given a dataset$\n",
        "\\mathscr{D}=\\{(x_i,y_i)\\}_{i=1}^N \\quad y_i\\in\\{0,1\\},\n",
        "$ Logistic Regression models $\n",
        "p(y_i=1\\mid x_i;w)=\\sigma(w^\\top x_i),\\quad\n",
        "\\sigma(z)=\\frac{1}{1+e^{-z}}$.\n",
        "\n",
        "### Objective\n",
        "- **MLE:** maximize likelihood $p(\\mathscr{D}\\mid w)$  \n",
        "- **MAP:** maximize posterior $p(w\\mid\\mathscr{D}) \\propto p(\\mathscr{D}\\mid w)p(w)$ -> MAP can be interpreted as **MLE + regularization**.\n",
        "\n",
        "### Regularization\n",
        "- **MLE:** no explicit regularization term  \n",
        "- **MAP:** adds prior-based regularization ($-\\log p(w)$)\n",
        "\n",
        "### When it helps\n",
        "- **MLE:** works well with large datasets  \n",
        "- **MAP:** often better for small datasets / high-dimensional features because priors reduce overfitting\n",
        "\n",
        "\n",
        "### Reference\n",
        "[1] S. Aswani, “IEOR 165 – Lecture 8: Regularization (Maximum A Posteriori Estimation),” University of California, Berkeley. [Online]. Available: https://aswani.ieor.berkeley.edu/teaching/SP16/165/lecture_notes/ieor165_lec8.pdf\n",
        "\n",
        "\n",
        "[2] A. Ng, “CS229 Lecture Notes: Logistic Regression,” Stanford University. [Online]. Available: https://cs229.stanford.edu/notes2020spring/cs229-notes1.pdf\n",
        "\n",
        "[3] X. Fern, “Logistic Regression,” Oregon State University, CS534 Lecture Notes. [Online]. Available: https://web.engr.oregonstate.edu/~xfern/classes/cs534-18/Logistic-Regression-3-updated.pdf\n"
      ],
      "metadata": {
        "id": "H2fN8MT3aQ7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1.2"
      ],
      "metadata": {
        "id": "Xt7XmW1PU9oU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a machine learning problem you wish to solve using Logistic Regression.\n",
        "As someone interested in weather tasks, I chose to work with weather prediction, a domain where classification models can provide practical value for planning and risk management. In this project, we use the **Weather Dataset (Rattle Package)**, which contains historical daily weather observations collected from multiple locations in Australia. Each record includes meteorological measurements such as temperature, humidity, atmospheric pressure, wind direction/speed, rainfall, and cloud coverage.\n",
        "\n",
        "The goal of this project is to solve a **binary classification** problem: predicting whether it will **rain tomorrow** (`RainTomorrow = Yes/No`) based on weather conditions observed today. To address this, we apply **logistic regression**, which is a suitable model because the prediction target is binary and logistic regression naturally outputs a probability value \\(P(y=1\\mid x)\\) through a sigmoid activation function applied to a linear combination of the input features. This probability can then be compared against a threshold to determine the predicted class. In addition to being computationally efficient, logistic regression also provides interpretable feature coefficients, allowing us to understand which weather factors are most strongly associated with rainfall on the following day.\n",
        "\n",
        "\n",
        "**Goal**: Predict whether it will rain tomorrow using historical weather measurements.\n",
        "\n",
        "**Dataset (X, y)**: Using the Kaggle dataset: **Weather Dataset (Rattle Package)**  (loaded locally as `weatherAUS.csv`). Link to dataset: https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package\n",
        "\n",
        "**Target variable (y)**: The dataset provides a binary label: `RainTomorrow ∈ {Yes, No}` We define: $y_i =\n",
        "\\begin{cases}\n",
        "1, & \\text{if RainTomorrow = Yes}\\\\\n",
        "0, & \\text{if RainTomorrow = No}\n",
        "\\end{cases}$ So: $y = \\texttt{RainTomorrow}$\n",
        "\n",
        "**Input features (X)**\n",
        "For each observation \\(i\\), we define the feature vector \\(x_i\\) using weather-related measurements from the same day.\n",
        "\n",
        "A typical choice of \\(X\\) is: $x_i = [\\text{Location},\\text{MinTemp},\\text{MaxTemp},\\text{Rainfall},\\text{Evaporation},\\text{Sunshine},\n",
        "\\text{WindGustDir},\\text{WindGustSpeed},\\text{WindDir9am},\\text{WindDir3pm},\n",
        "\\text{WindSpeed9am},\\text{WindSpeed3pm},\\text{Humidity9am},\\text{Humidity3pm},\n",
        "\\text{Pressure9am},\\text{Pressure3pm},\\text{Cloud9am},\\text{Cloud3pm},\n",
        "\\text{Temp9am},\\text{Temp3pm},\\text{RainToday}]$ where categorical variables such as `Location`, `WindGustDir`, etc. are encoded using **one-hot encoding**. We exclude `Date` since it is not a physical measurement by itself and is typically replaced by engineered temporal features (month/season) if needed.\n",
        "\n",
        "## Why Logistic Regression is the Best Choice\n",
        "\n",
        "1. `RainTomorrow` is a two-class label (Yes/No), which directly matches Logistic Regression.\n",
        "\n",
        "2. Second, Interpretable coefficients Logistic Regression provides interpretable weights: positive coefficient → increases rain probability\n",
        "& negative coefficient → decreases rain probability. This is valuable for weather-related decision support (e.g., agriculture, transportation).\n",
        "\n",
        "3. This dataset contains tens of thousands of rows. Logistic Regression trains quickly, handles large datasets well, and supports regularization (L1/L2) to reduce overfitting.\n",
        "\n",
        "4. Instead of only predicting a class label, Logistic Regression outputs:\n",
        "$P(\\text{RainTomorrow}=\\text{Yes}\\mid x)$ which is useful for risk-based decisions (e.g., predicting rain with confidence thresholds).\n",
        "\n",
        "## Comparison to Another Linear Classification Model (Linear SVM)\n",
        "### Objective functions\n",
        "- **Logistic Regression**: $\\min_{w,b} \\sum_{i=1}^N \\log\\bigl(1+\\exp(-y_i(w^\\top x_i+b))\\bigr)$\n",
        "- **Linear SVM**: $\\min_{w,b} \\sum_{i=1}^N \\max(0, 1 - y_i(w^\\top x_i + b))$\n",
        "\n",
        "### Output\n",
        "- **Logistic Regression**: Probability \\(P(y=1|x)\\)\n",
        "- **Linear SVM**: Class score (not probability)\n",
        "\n",
        "### Loss\n",
        "- **Logistic Regression**: Log loss\n",
        "- **Linear SVM**: Hinge loss\n",
        "\n",
        "### Interpretability\n",
        "- **Logistic Regression**: High\n",
        "- **Linear SVM**: Medium\n",
        "\n",
        "### Best for\n",
        "- **Logistic Regression**: Probabilistic risk estimation\n",
        "- **Linear SVM**: Maximum-margin separation\n",
        "\n",
        "## Why Logistic Regression is preferred here\n",
        "In weather prediction, **probability outputs** are often necessary (e.g., “70% chance of rain tomorrow”), so Logistic Regression is more suitable than SVM unless extra probability calibration is added.\n",
        "\n",
        "## Reference\n",
        "[1] X. Fern, “Logistic Regression,” Oregon State University, CS534 Lecture Notes. [Online]. Available: https://web.engr.oregonstate.edu/~xfern/classes/cs534-18/Logistic-Regression-3-updated.pdf\n",
        "\n",
        "[2] Cornell University, “CS4780 Lecture Note 06: Logistic Regression,” Dept. of Computer Science. [Online]. Available: https://www.cs.cornell.edu/courses/cs4780/2023fa/lectures/lecturenote06.html\n",
        "\n",
        "[3] A. Ng, “CS229 Lecture Notes: Support Vector Machines,” Stanford University. [Online]. Available: https://cs229.stanford.edu/notes2020spring/cs229-notes2.pdf\n",
        "\n",
        "[4] D. Klein, “CS 180 Lecture Notes: Support Vector Machines,” University of California, Berkeley. [Online]. Available: https://people.eecs.berkeley.edu/~klein/cs180f13/lectures/lec14.pdf\n",
        "\n",
        "[5] M. Collins, “Lecture Notes: Support Vector Machines,” Carnegie Mellon University. [Online]. Available: http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf\n"
      ],
      "metadata": {
        "id": "WtwTOsQ1JWQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1.3"
      ],
      "metadata": {
        "id": "OQXdX_S_YfES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mapping dataset variables to equation variables\n",
        "\n",
        "In the logistic regression formulation shown in the derivation, the binary classification dataset is written as: $$\\mathscr{D} = \\{(x_i, y_i)\\}_{i=1}^{N}, \\quad x_i \\in \\mathbb{R}^d,\\quad y_i \\in \\{0,1\\}.$$\n",
        "\n",
        "In this dataset:\n",
        "\n",
        "- **$N$** = number of valid daily observations used for training (after filtering missing labels, etc.)\n",
        "- **$x_i$** = feature vector derived from the $i$-th row of `weatherAUS.csv`. After preprocessing (e.g., one-hot encoding categorical variables), each example becomes a vector: $x_i \\in \\mathbb{R}^d$ where $d$ is the total number of numerical features plus the number of one-hot encoded categories.\n",
        "- **$y_i$** = label derived from the $i$-th row, specifically the column `RainTomorrow ∈ {Yes, No}` $y_i =\n",
        "\\begin{cases}\n",
        "1, & \\text{if RainTomorrow = Yes}\\\\\n",
        "0, & \\text{if RainTomorrow = No}\n",
        "\\end{cases}$ Thus, $y_i\\in\\{0,1\\}$ matches the Bernoulli assumption used in the MLE derivation.\n",
        "\n",
        "\n",
        "## Connection to Logistic Regression Probability Model\n",
        "\n",
        "The derivation assumes logistic regression models: $p(y_i=1 \\mid x_i; w) = \\sigma(w^\\top x_i), \\quad \\sigma(z)=\\frac{1}{1+e^{-z}}$.\n",
        "\n",
        "In this dataset, this corresponds to: $p(\\text{RainTomorrow=Yes} \\mid \\text{weather features today})$\n",
        "\n",
        "meaning logistic regression outputs the probability that tomorrow will be rainy based on today's meteorological conditions.\n",
        "\n",
        "The conditional probability for the negative class is: $p(y_i=0 \\mid x_i;w) = 1-\\sigma(w^\\top x_i)$, which corresponds to the probability of `RainTomorrow = No`.\n",
        "\n",
        "## Assumptions in part 1.1\n",
        "\n",
        "### Assumption 1: Binary labels follow a Bernoulli distribution\n",
        "The derivation states each $y_i$ is Bernoulli:\n",
        "$y_i \\sim \\text{Bernoulli}(p_i),\\quad p_i=\\sigma(w^\\top x_i)$. This is appropriate because `RainTomorrow` is binary and can be represented as $0/1$.\n",
        "\n",
        "### Assumption 2: Conditional independence of labels given features\n",
        "Logistic regression assumes that once we condition on $x_i$, the label $y_i$ depends only on $x_i$ and parameters $w$, not on other training examples. This supports writing the likelihood as a product: $\\mathscr{L}(w)=\\prod_{i=1}^{N}p(y_i\\mid x_i; w)$.\n",
        "\n",
        "### Assumption 3: i.i.d. samples\n",
        "The derivation explicitly assumes samples are i.i.d.: $\\{(x_i,y_i)\\}_{i=1}^N \\text{ are i.i.d.}$. We treat each row as an independent sample after feature extraction.\n",
        "\n",
        "### Assumption 4: Linear decision boundary in feature space\n",
        "Logistic regression uses a linear score $w^\\top x_i$, which implies a linear boundary: $w^\\top x + b = 0$. Thus, we assume that a linear combination of meteorological features is sufficient to separate rainy vs. non-rainy outcomes reasonably well.\n",
        "\n",
        "### Assumption 5: Correct preprocessing makes $x_i\\in\\mathbb{R}^d$\n",
        "The mathematical form requires all features to be numeric.\n",
        "1. categorical features (e.g., `Location`, wind directions) are converted via one-hot encoding\n",
        "2. missing values are either removed or imputed\n",
        "3. all features are aligned into a consistent numeric feature vector"
      ],
      "metadata": {
        "id": "aVn7R1zXZH4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Raw GitHub link for the weatherAUS.csv dataset\n",
        "github_url = 'https://raw.githubusercontent.com/manishabajaj/Weather-Prediction-with-Deep-Learning-and-Transfer-Learning/master/weatherAUS.csv'\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv(github_url)\n",
        "\n",
        "print(f\"Dataset loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "uIUIZjEufwkT",
        "outputId": "ae3f9245-4ccd-49ae-e0a7-c2a470da63a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2731899243.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the dataset into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgithub_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Dataset and Advanced EDA"
      ],
      "metadata": {
        "id": "1eLY4m1oUwi1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s3k76DL9ZwH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "# Replace 'my_folder/my_data.csv' with your file's actual path\n",
        "file_path = '/content/drive/MyDrive/'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "Z0vknJ9SXw7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0dv813QXm01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SCMkhWe2UxFd"
      }
    }
  ]
}